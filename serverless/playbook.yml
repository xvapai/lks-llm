---
- name: Install Ollama directly on host (CPU only) and setup NFS
  hosts: all
  become: true
  vars:
    efs_ip: "YOUR_EFS_IP"
    share_path: "/share"
    llm_data: "/share/llm"
    llm_tmp: "/share/tmp"
  tasks:
    - name: Update apt cache
      apt:
        update_cache: yes
      tags: [always]

    - name: Install necessary packages
      apt:
        name: 
          - nfs-common
          - curl
          - unzip
          - gpg
        state: present
      tags: [packages]

    # NFS Setup
    - name: Create share directory
      file:
        path: "{{ share_path }}"
        state: directory
        owner: root
        group: root
        mode: '0755'
      tags: [nfs]

    - name: Check if NFS is already mounted
      shell: mount | grep -q '{{ efs_ip }}:/'
      register: nfs_mounted
      ignore_errors: true
      changed_when: false
      tags: [nfs]

    - name: Mount NFS
      mount:
        src: "{{ efs_ip }}:/"
        path: "{{ share_path }}"
        fstype: nfs4
        opts: defaults,_netdev
        state: mounted
      when: nfs_mounted.rc != 0
      tags: [nfs]

    - name: Add mount entry to /etc/fstab
      lineinfile:
        path: /etc/fstab
        line: "{{ efs_ip }}:/ {{ share_path }} nfs4 defaults,_netdev 0 0"
        state: present
      tags: [nfs]

    - name: Ensure NFS mount is accessible
      file:
        path: "{{ share_path }}"
        state: directory
        mode: '0755'
      tags: [nfs]

    # Install Ollama using official script (CPU only)
    - name: Install Ollama
      shell: curl -fsSL https://ollama.com/install.sh | sh
      args:
        executable: /bin/bash
      tags: [ollama]

    # Run Ollama as a systemd service
    - name: Create systemd service for Ollama
      copy:
        dest: /etc/systemd/system/ollama.service
        content: |
          [Unit]
          Description=Ollama LLM Service (CPU Only)
          After=network.target

          [Service]
          Type=simple
          ExecStart=/usr/local/bin/ollama serve --data {{ llm_data }} --tmp {{ llm_tmp }}
          Restart=always
          User=root

          [Install]
          WantedBy=multi-user.target
      tags: [ollama]

    - name: Reload systemd
      systemd:
        daemon_reload: yes
      tags: [ollama]

    - name: Enable and start Ollama service
      systemd:
        name: ollama
        state: started
        enabled: yes
      tags: [ollama]
